# -*- coding: utf-8 -*-
"""
ç»Ÿä¸€è¯­ä¹‰æ“ä½œå·¥å…·

å°†è¯­ä¹‰åº“è¡¨çš„æ“ä½œè§†ä¸ºä¸€ä¸ªæ•´ä½“ï¼Œæ ¹æ®æƒé™è‡ªåŠ¨é€‰æ‹©åœ¨è¯­ä¹‰åº“æˆ–ä¸šåŠ¡åº“çš„è¯­ä¹‰è¡¨ä¸­è¯»å†™
"""

from typing import Dict, List, Any, Optional
import structlog
from mcp.types import Tool, TextContent
from datetime import datetime

from database.connection_manager import ConnectionManager
from database.metadata_manager import MetadataManager
from scanner.semantic_analyzer import SemanticAnalyzer
from storage.local_semantic_storage import LocalSemanticStorage
from storage.semantic_file_manager import SemanticFileManager
from storage.config import get_config
from utils.error_handler import with_error_handling, with_retry, RetryConfig


logger = structlog.get_logger(__name__)


class UnifiedSemanticTool:
    """ç»Ÿä¸€è¯­ä¹‰æ“ä½œå·¥å…·"""
    
    def __init__(self, connection_manager: ConnectionManager, 
                 metadata_manager: MetadataManager,
                 semantic_analyzer: SemanticAnalyzer):
        self.connection_manager = connection_manager
        self.metadata_manager = metadata_manager
        self.semantic_analyzer = semantic_analyzer
        
        # åˆå§‹åŒ–æœ¬åœ°å­˜å‚¨ç»„ä»¶
        self.config = get_config()
        self.local_storage = LocalSemanticStorage(self.config)
        self.file_manager = SemanticFileManager(self.config)
    
    def get_tool_definition(self) -> Tool:
        """è·å–å·¥å…·å®šä¹‰"""
        return Tool(
            name="unified_semantic_operations",
            description="ç»Ÿä¸€çš„è¯­ä¹‰æ“ä½œå·¥å…·ï¼Œæ ¹æ®æƒé™è‡ªåŠ¨é€‰æ‹©è¯­ä¹‰åº“æˆ–ä¸šåŠ¡åº“è¿›è¡Œè¯­ä¹‰ä¿¡æ¯çš„è¯»å†™æ“ä½œ",
            inputSchema={
                "type": "object",
                "properties": {
                    "action": {
                        "type": "string",
                        "enum": [
                            "view_semantics", "update_semantics", "batch_analyze", 
                            "search_semantics", "suggest_semantics", "confirm_semantics",
                            "feedback_learning", "get_pending_confirmations", "reject_suggestions"
                        ],
                        "description": "æ“ä½œç±»å‹ï¼šview_semantics=æŸ¥çœ‹è¯­ä¹‰ï¼Œupdate_semantics=æ›´æ–°è¯­ä¹‰ï¼Œbatch_analyze=æ‰¹é‡åˆ†æï¼Œsearch_semantics=æœç´¢è¯­ä¹‰ï¼Œsuggest_semantics=è¯­ä¹‰å»ºè®®ï¼Œconfirm_semantics=ç¡®è®¤è¯­ä¹‰ï¼Œfeedback_learning=åé¦ˆå­¦ä¹ ï¼Œget_pending_confirmations=è·å–å¾…ç¡®è®¤é¡¹ï¼Œreject_suggestions=æ‹’ç»å»ºè®®"
                    },
                    "instance_id": {
                        "type": "string",
                        "description": "MongoDBå®ä¾‹åç§°ï¼ˆå®é™…ä¸ºå®ä¾‹åç§°ï¼ŒéIDï¼‰"
                    },
                    "database_name": {
                        "type": "string",
                        "description": "æ•°æ®åº“åç§°"
                    },
                    "collection_name": {
                        "type": "string",
                        "description": "é›†åˆåç§°"
                    },
                    "field_path": {
                        "type": "string",
                        "description": "å­—æ®µè·¯å¾„"
                    },
                    "business_meaning": {
                        "type": "string",
                        "description": "ä¸šåŠ¡å«ä¹‰"
                    },
                    "search_term": {
                        "type": "string",
                        "description": "æœç´¢å…³é”®è¯"
                    },
                    "query_description": {
                        "type": "string",
                        "description": "æŸ¥è¯¢æè¿°"
                    },
                    "confidence_threshold": {
                        "type": "number",
                        "description": "ç½®ä¿¡åº¦é˜ˆå€¼",
                        "default": 0.6,
                        "minimum": 0,
                        "maximum": 1
                    },
                    "confirmations": {
                        "type": "array",
                        "description": "æ‰¹é‡ç¡®è®¤åˆ—è¡¨",
                        "items": {
                            "type": "object",
                            "properties": {
                                "field_path": {"type": "string"},
                                "database_name": {"type": "string"},
                                "collection_name": {"type": "string"},
                                "confirmed_meaning": {"type": "string"},
                                "action": {
                                    "type": "string",
                                    "enum": ["confirm", "reject", "modify"]
                                }
                            },
                            "required": ["field_path", "database_name", "collection_name", "action"]
                        }
                    },
                    "field_corrections": {
                        "type": "array",
                        "description": "å­—æ®µè¯­ä¹‰çº æ­£åˆ—è¡¨",
                        "items": {
                            "type": "object",
                            "properties": {
                                "field_path": {"type": "string"},
                                "current_meaning": {"type": "string"},
                                "correct_meaning": {"type": "string"},
                                "confidence": {"type": "number", "minimum": 0, "maximum": 1}
                            },
                            "required": ["field_path", "correct_meaning"]
                        }
                    },
                    "feedback_type": {
                        "type": "string",
                        "enum": ["semantic_correction", "field_meaning_clarification", "query_result_unexpected"],
                        "description": "åé¦ˆç±»å‹"
                    },
                    "feedback_description": {
                        "type": "string",
                        "description": "åé¦ˆè¯´æ˜"
                    },
                    "limit": {
                        "type": "integer",
                        "description": "ç»“æœé™åˆ¶æ•°é‡",
                        "default": 20,
                        "minimum": 1,
                        "maximum": 100
                    }
                },
                "required": ["action", "instance_id"]
            }
        )
    
    @with_error_handling("ç»Ÿä¸€è¯­ä¹‰æ“ä½œ")
    async def execute(self, arguments: Dict[str, Any]) -> List[TextContent]:
        """æ‰§è¡Œç»Ÿä¸€è¯­ä¹‰æ“ä½œ"""
        action = arguments["action"]
        instance_id = arguments["instance_id"]
        
        logger.info("æ‰§è¡Œç»Ÿä¸€è¯­ä¹‰æ“ä½œ", action=action, instance_id=instance_id)
        
        # éªŒè¯å®ä¾‹å¹¶åˆå§‹åŒ–å…ƒæ•°æ®
        if not await self._validate_and_init_instance(instance_id):
            return [TextContent(
                type="text",
                text=f"å®ä¾‹ '{instance_id}' ä¸å­˜åœ¨æˆ–æ— æ³•åˆå§‹åŒ–å…ƒæ•°æ®åº“ã€‚è¯·ä½¿ç”¨ discover_instances å·¥å…·æŸ¥çœ‹å¯ç”¨å®ä¾‹ã€‚"
            )]
        
        # æ ¹æ®æ“ä½œç±»å‹æ‰§è¡Œç›¸åº”åŠŸèƒ½
        if action == "view_semantics":
            return await self._handle_view_semantics(arguments)
        elif action == "update_semantics":
            return await self._handle_update_semantics(arguments)
        elif action == "batch_analyze":
            return await self._handle_batch_analyze(arguments)
        elif action == "search_semantics":
            return await self._handle_search_semantics(arguments)
        elif action == "suggest_semantics":
            return await self._handle_suggest_semantics(arguments)
        elif action == "confirm_semantics":
            return await self._handle_confirm_semantics(arguments)
        elif action == "feedback_learning":
            return await self._handle_feedback_learning(arguments)
        elif action == "get_pending_confirmations":
            return await self._handle_get_pending_confirmations(arguments)
        elif action == "reject_suggestions":
            return await self._handle_reject_suggestions(arguments)
        else:
            return [TextContent(
                type="text",
                text=f"ä¸æ”¯æŒçš„æ“ä½œç±»å‹: {action}"
            )]
    
    @with_retry(RetryConfig(max_attempts=3, base_delay=1.0))
    async def _validate_and_init_instance(self, instance_id: str) -> bool:
        """éªŒè¯å®ä¾‹å¹¶åˆå§‹åŒ–å…ƒæ•°æ®"""
        # éªŒè¯å®ä¾‹å­˜åœ¨
        if not self.connection_manager.has_instance(instance_id):
            return False
        
        # ç¡®ä¿å®ä¾‹å…ƒæ•°æ®å·²åˆå§‹åŒ–
        return await self.metadata_manager.init_instance_metadata(instance_id)
    
    @with_error_handling("æŸ¥çœ‹è¯­ä¹‰æ“ä½œ")
    async def _handle_view_semantics(self, arguments: Dict[str, Any]) -> List[TextContent]:
        """å¤„ç†æŸ¥çœ‹è¯­ä¹‰æ“ä½œ"""
        instance_id = arguments["instance_id"]
        database_name = arguments.get("database_name")
        collection_name = arguments.get("collection_name")
        field_path = arguments.get("field_path")
        
        if field_path and database_name and collection_name:
            # æŸ¥çœ‹ç‰¹å®šå­—æ®µçš„è¯­ä¹‰ä¿¡æ¯
            return await self._view_field_semantics(instance_id, database_name, collection_name, field_path)
        elif database_name and collection_name:
            # æŸ¥çœ‹é›†åˆçš„æ‰€æœ‰å­—æ®µè¯­ä¹‰
            return await self._view_collection_semantics(instance_id, database_name, collection_name)
        elif database_name:
            # æŸ¥çœ‹æ•°æ®åº“çš„è¯­ä¹‰è¦†ç›–æƒ…å†µ
            return await self._view_database_semantics(instance_id, database_name)
        else:
            # æŸ¥çœ‹å®ä¾‹çš„è¯­ä¹‰è¦†ç›–æƒ…å†µ
            return await self._view_instance_semantics(instance_id)
    
    @with_error_handling("æ›´æ–°è¯­ä¹‰æ“ä½œ")
    @with_retry(RetryConfig(max_attempts=2, base_delay=1.0))
    async def _handle_update_semantics(self, arguments: Dict[str, Any]) -> List[TextContent]:
        """å¤„ç†æ›´æ–°è¯­ä¹‰æ“ä½œ"""
        instance_id = arguments["instance_id"]
        database_name = arguments.get("database_name")
        collection_name = arguments.get("collection_name")
        field_path = arguments.get("field_path")
        business_meaning = arguments.get("business_meaning")
        
        if not all([database_name, collection_name, field_path, business_meaning]):
            return [TextContent(
                type="text",
                text="æ›´æ–°è¯­ä¹‰æ“ä½œéœ€è¦æä¾› database_name, collection_name, field_path å’Œ business_meaning å‚æ•°ã€‚"
            )]
        
        # è·å–å®ä¾‹ä¿¡æ¯
        instance_info = await self.metadata_manager.get_instance_by_name(instance_id, instance_id)
        if not instance_info:
            return [TextContent(
                type="text",
                text=f"å®ä¾‹ '{instance_id}' ä¸å­˜åœ¨"
            )]
        
        instance_obj_id = instance_info["_id"]
        
        # ä½¿ç”¨ç»Ÿä¸€çš„è¯­ä¹‰æ›´æ–°æ–¹æ³•ï¼ˆè‡ªåŠ¨é€‰æ‹©è¯­ä¹‰åº“æˆ–ä¸šåŠ¡åº“ï¼‰
        success = await self.metadata_manager.update_field_semantics(
            instance_id, instance_obj_id, database_name, collection_name, 
            field_path, business_meaning
        )
        
        if success:
            result_text = f"âœ… æˆåŠŸæ›´æ–°å­—æ®µè¯­ä¹‰\n\n"
            result_text += f"- **å®ä¾‹**: {instance_id}\n"
            result_text += f"- **æ•°æ®åº“**: {database_name}\n"
            result_text += f"- **é›†åˆ**: {collection_name}\n"
            result_text += f"- **å­—æ®µ**: {field_path}\n"
            result_text += f"- **ä¸šåŠ¡å«ä¹‰**: {business_meaning}\n\n"
            result_text += f"ğŸ’¡ ç³»ç»Ÿå·²è‡ªåŠ¨é€‰æ‹©æœ€ä½³å­˜å‚¨ä½ç½®ï¼ˆè¯­ä¹‰åº“æˆ–ä¸šåŠ¡åº“ï¼‰è¿›è¡Œæ›´æ–°ã€‚"
            
            logger.info(
                "å­—æ®µè¯­ä¹‰æ›´æ–°æˆåŠŸ",
                instance_id=instance_id,
                database=database_name,
                collection=collection_name,
                field_path=field_path
            )
        else:
            result_text = f"âŒ æ›´æ–°å­—æ®µè¯­ä¹‰å¤±è´¥\n\n"
            result_text += f"è¯·æ£€æŸ¥å­—æ®µè·¯å¾„æ˜¯å¦æ­£ç¡®ï¼Œæˆ–å­—æ®µæ˜¯å¦å­˜åœ¨äºé›†åˆä¸­ã€‚"
        
        return [TextContent(type="text", text=result_text)]
    
    @with_error_handling("æ‰¹é‡åˆ†ææ“ä½œ")
    @with_retry(RetryConfig(max_attempts=2, base_delay=2.0))
    async def _handle_batch_analyze(self, arguments: Dict[str, Any]) -> List[TextContent]:
        """å¤„ç†æ‰¹é‡åˆ†ææ“ä½œ"""
        instance_id = arguments["instance_id"]
        database_name = arguments.get("database_name")
        collection_name = arguments.get("collection_name")
        
        if not all([database_name, collection_name]):
            return [TextContent(
                type="text",
                text="æ‰¹é‡åˆ†ææ“ä½œéœ€è¦æä¾› database_name å’Œ collection_name å‚æ•°ã€‚"
            )]
        
        # æ‰§è¡Œæ‰¹é‡è¯­ä¹‰åˆ†æ
        analysis_result = await self.semantic_analyzer.batch_analyze_collection(
            instance_id, database_name, collection_name
        )
        
        result_text = f"## æ‰¹é‡è¯­ä¹‰åˆ†æç»“æœ\n\n"
        result_text += f"- **å®ä¾‹**: {instance_id}\n"
        result_text += f"- **æ•°æ®åº“**: {database_name}\n"
        result_text += f"- **é›†åˆ**: {collection_name}\n\n"
        
        if analysis_result.get("success"):
            analyzed_fields = analysis_result.get("analyzed_fields", [])
            result_text += f"### åˆ†æç»Ÿè®¡\n\n"
            result_text += f"- **åˆ†æå­—æ®µæ•°**: {len(analyzed_fields)}\n"
            result_text += f"- **æˆåŠŸè¯†åˆ«è¯­ä¹‰**: {len([f for f in analyzed_fields if f.get('suggested_meaning')])}\n\n"
            
            if analyzed_fields:
                result_text += f"### å­—æ®µè¯­ä¹‰åˆ†æç»“æœ\n\n"
                for field in analyzed_fields[:10]:  # æ˜¾ç¤ºå‰10ä¸ªå­—æ®µ
                    field_path = field.get('field_path', '')
                    suggested_meaning = field.get('suggested_meaning', 'æœªè¯†åˆ«')
                    confidence = field.get('confidence', 0.0)
                    
                    result_text += f"**{field_path}**\n"
                    result_text += f"- å»ºè®®è¯­ä¹‰: {suggested_meaning}\n"
                    result_text += f"- ç½®ä¿¡åº¦: {confidence:.2f}\n\n"
            
            result_text += f"ğŸ’¡ è¯­ä¹‰ä¿¡æ¯å·²è‡ªåŠ¨å­˜å‚¨åˆ°æœ€ä½³ä½ç½®ï¼ˆè¯­ä¹‰åº“æˆ–ä¸šåŠ¡åº“ï¼‰ã€‚"
        else:
            result_text += f"âŒ æ‰¹é‡åˆ†æå¤±è´¥: {analysis_result.get('error', 'æœªçŸ¥é”™è¯¯')}"
        
        return [TextContent(type="text", text=result_text)]
    
    @with_error_handling("æœç´¢è¯­ä¹‰æ“ä½œ")
    async def _handle_search_semantics(self, arguments: Dict[str, Any]) -> List[TextContent]:
        """å¤„ç†æœç´¢è¯­ä¹‰æ“ä½œ"""
        instance_id = arguments["instance_id"]
        search_term = arguments.get("search_term")
        
        if not search_term:
            return [TextContent(
                type="text",
                text="æœç´¢è¯­ä¹‰æ“ä½œéœ€è¦æä¾› search_term å‚æ•°ã€‚"
            )]
        
        # ä½¿ç”¨ç»Ÿä¸€çš„è¯­ä¹‰æœç´¢æ–¹æ³•ï¼ˆåŒæ—¶æœç´¢è¯­ä¹‰åº“å’Œä¸šåŠ¡åº“ï¼‰
        search_results = await self.metadata_manager.search_fields_by_meaning(
            instance_id, search_term
        )
        
        result_text = f"## è¯­ä¹‰æœç´¢ç»“æœ\n\n"
        result_text += f"- **å®ä¾‹**: {instance_id}\n"
        result_text += f"- **æœç´¢å…³é”®è¯**: {search_term}\n"
        result_text += f"- **æ‰¾åˆ°ç»“æœ**: {len(search_results)} æ¡\n\n"
        
        if search_results:
            # æŒ‰æ•°æ®åº“åˆ†ç»„æ˜¾ç¤ºç»“æœ
            grouped_results = {}
            for result in search_results:
                db_name = result.get('database_name', 'æœªçŸ¥')
                if db_name not in grouped_results:
                    grouped_results[db_name] = []
                grouped_results[db_name].append(result)
            
            for db_name, db_results in grouped_results.items():
                result_text += f"### ğŸ“‚ æ•°æ®åº“: {db_name}\n\n"
                
                for result in db_results[:5]:  # æ¯ä¸ªæ•°æ®åº“æ˜¾ç¤ºå‰5ä¸ªç»“æœ
                    collection_name = result.get('collection_name', 'æœªçŸ¥')
                    field_path = result.get('field_path', 'æœªçŸ¥')
                    business_meaning = result.get('business_meaning', 'æœªå®šä¹‰')
                    semantic_source = result.get('semantic_source', 'æœªçŸ¥')
                    
                    result_text += f"**{collection_name}.{field_path}**\n"
                    result_text += f"- è¯­ä¹‰: {business_meaning}\n"
                    result_text += f"- æ¥æº: {semantic_source}\n\n"
            
            result_text += f"ğŸ’¡ æœç´¢ç»“æœæ¥è‡ªè¯­ä¹‰åº“å’Œä¸šåŠ¡åº“çš„ç»¼åˆæŸ¥è¯¢ã€‚"
        else:
            result_text += f"æœªæ‰¾åˆ°åŒ…å«å…³é”®è¯ '{search_term}' çš„è¯­ä¹‰ä¿¡æ¯ã€‚"
        
        return [TextContent(type="text", text=result_text)]
    
    async def _handle_suggest_semantics(self, arguments: Dict[str, Any]) -> List[TextContent]:
        """å¤„ç†è¯­ä¹‰å»ºè®®æ“ä½œ"""
        instance_id = arguments["instance_id"]
        query_description = arguments.get("query_description")
        
        if not query_description:
            return [TextContent(
                type="text",
                text="è¯­ä¹‰å»ºè®®æ“ä½œéœ€è¦æä¾› query_description å‚æ•°ã€‚"
            )]
        
        try:
            # åŸºäºæŸ¥è¯¢æè¿°ç”Ÿæˆè¯­ä¹‰å»ºè®®
            suggestions = await self.semantic_analyzer.suggest_semantics_for_query(
                instance_id, query_description
            )
            
            result_text = f"## è¯­ä¹‰å»ºè®®\n\n"
            result_text += f"- **å®ä¾‹**: {instance_id}\n"
            result_text += f"- **æŸ¥è¯¢æè¿°**: {query_description}\n\n"
            
            if suggestions:
                result_text += f"### å»ºè®®çš„ç›¸å…³å­—æ®µ\n\n"
                for suggestion in suggestions[:10]:
                    field_info = suggestion.get('field_info', {})
                    suggested_meaning = suggestion.get('suggested_meaning', 'æœªçŸ¥')
                    confidence = suggestion.get('confidence', 0.0)
                    
                    result_text += f"**{field_info.get('database_name', '')}.{field_info.get('collection_name', '')}.{field_info.get('field_path', '')}**\n"
                    result_text += f"- å»ºè®®è¯­ä¹‰: {suggested_meaning}\n"
                    result_text += f"- ç½®ä¿¡åº¦: {confidence:.2f}\n\n"
            else:
                result_text += f"æš‚æ— ç›¸å…³çš„è¯­ä¹‰å»ºè®®ã€‚"
            
            return [TextContent(type="text", text=result_text)]
            
        except Exception as e:
            logger.error("ç”Ÿæˆè¯­ä¹‰å»ºè®®å¤±è´¥", error=str(e))
            return [TextContent(type="text", text=f"ç”Ÿæˆè¯­ä¹‰å»ºè®®æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")]
    
    async def _handle_confirm_semantics(self, arguments: Dict[str, Any]) -> List[TextContent]:
        """å¤„ç†ç¡®è®¤è¯­ä¹‰æ“ä½œ"""
        instance_id = arguments["instance_id"]
        confirmations = arguments.get("confirmations", [])
        
        if not confirmations:
            return [TextContent(
                type="text",
                text="ç¡®è®¤è¯­ä¹‰æ“ä½œéœ€è¦æä¾› confirmations å‚æ•°ã€‚"
            )]
        
        try:
            # è·å–å®ä¾‹ä¿¡æ¯
            instance_info = await self.metadata_manager.get_instance_by_name(instance_id, instance_id)
            if not instance_info:
                return [TextContent(
                    type="text",
                    text=f"å®ä¾‹ '{instance_id}' ä¸å­˜åœ¨"
                )]
            
            instance_obj_id = instance_info["_id"]
            
            result_text = f"## æ‰¹é‡è¯­ä¹‰ç¡®è®¤ç»“æœ\n\n"
            result_text += f"- **å®ä¾‹**: {instance_id}\n"
            result_text += f"- **å¤„ç†é¡¹ç›®**: {len(confirmations)} ä¸ª\n\n"
            
            confirmed_count = 0
            rejected_count = 0
            failed_count = 0
            
            for confirmation in confirmations:
                field_path = confirmation["field_path"]
                database_name = confirmation["database_name"]
                collection_name = confirmation["collection_name"]
                action = confirmation["action"]
                
                try:
                    if action == "confirm":
                        confirmed_meaning = confirmation.get("confirmed_meaning", "")
                        if confirmed_meaning:
                            success = await self.metadata_manager.update_field_semantics(
                                instance_id, instance_obj_id, database_name, collection_name,
                                field_path, confirmed_meaning
                            )
                            if success:
                                confirmed_count += 1
                            else:
                                failed_count += 1
                    elif action == "reject":
                        # æ ‡è®°ä¸ºæ‹’ç»çŠ¶æ€
                        rejected_count += 1
                    elif action == "modify":
                        confirmed_meaning = confirmation.get("confirmed_meaning", "")
                        if confirmed_meaning:
                            success = await self.metadata_manager.update_field_semantics(
                                instance_id, instance_obj_id, database_name, collection_name,
                                field_path, confirmed_meaning
                            )
                            if success:
                                confirmed_count += 1
                            else:
                                failed_count += 1
                        
                except Exception as e:
                    logger.error(f"å¤„ç†ç¡®è®¤é¡¹å¤±è´¥: {field_path}", error=str(e))
                    failed_count += 1
            
            result_text += f"### å¤„ç†ç»Ÿè®¡\n\n"
            result_text += f"- **ç¡®è®¤æˆåŠŸ**: {confirmed_count} ä¸ª\n"
            result_text += f"- **æ‹’ç»**: {rejected_count} ä¸ª\n"
            result_text += f"- **å¤„ç†å¤±è´¥**: {failed_count} ä¸ª\n\n"
            result_text += f"ğŸ’¡ ç¡®è®¤çš„è¯­ä¹‰ä¿¡æ¯å·²è‡ªåŠ¨å­˜å‚¨åˆ°æœ€ä½³ä½ç½®ï¼ˆè¯­ä¹‰åº“æˆ–ä¸šåŠ¡åº“ï¼‰ã€‚"
            
            return [TextContent(type="text", text=result_text)]
            
        except Exception as e:
            logger.error("æ‰¹é‡ç¡®è®¤è¯­ä¹‰å¤±è´¥", error=str(e))
            return [TextContent(type="text", text=f"æ‰¹é‡ç¡®è®¤è¯­ä¹‰æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")]
    
    async def _handle_feedback_learning(self, arguments: Dict[str, Any]) -> List[TextContent]:
        """å¤„ç†åé¦ˆå­¦ä¹ æ“ä½œ"""
        instance_id = arguments["instance_id"]
        database_name = arguments.get("database_name")
        collection_name = arguments.get("collection_name")
        feedback_type = arguments.get("feedback_type")
        field_corrections = arguments.get("field_corrections", [])
        
        if not all([database_name, collection_name, feedback_type]):
            return [TextContent(
                type="text",
                text="åé¦ˆå­¦ä¹ æ“ä½œéœ€è¦æä¾› database_name, collection_name å’Œ feedback_type å‚æ•°ã€‚"
            )]
        
        try:
            # è·å–å®ä¾‹ä¿¡æ¯
            instance_info = await self.metadata_manager.get_instance_by_name(instance_id, instance_id)
            if not instance_info:
                return [TextContent(
                    type="text",
                    text=f"å®ä¾‹ '{instance_id}' ä¸å­˜åœ¨"
                )]
            
            instance_obj_id = instance_info["_id"]
            
            result_text = f"## åé¦ˆå­¦ä¹ ç»“æœ\n\n"
            result_text += f"- **å®ä¾‹**: {instance_id}\n"
            result_text += f"- **æ•°æ®åº“**: {database_name}\n"
            result_text += f"- **é›†åˆ**: {collection_name}\n"
            result_text += f"- **åé¦ˆç±»å‹**: {feedback_type}\n\n"
            
            updated_fields = []
            failed_updates = []
            
            # å¤„ç†å­—æ®µè¯­ä¹‰çº æ­£
            if field_corrections:
                result_text += f"### å­—æ®µè¯­ä¹‰çº æ­£å¤„ç†\n\n"
                
                for correction in field_corrections:
                    field_path = correction["field_path"]
                    correct_meaning = correction["correct_meaning"]
                    current_meaning = correction.get("current_meaning", "")
                    user_confidence = correction.get("confidence", 1.0)
                    
                    try:
                        # ä½¿ç”¨ç»Ÿä¸€çš„è¯­ä¹‰æ›´æ–°æ–¹æ³•
                        success = await self.metadata_manager.update_field_semantics(
                            instance_id, instance_obj_id, database_name, collection_name,
                            field_path, correct_meaning
                        )
                        
                        if success:
                            updated_fields.append({
                                "field_path": field_path,
                                "old_meaning": current_meaning,
                                "new_meaning": correct_meaning,
                                "confidence": user_confidence
                            })
                            
                            result_text += f"âœ… **{field_path}**: å·²æ›´æ–°\n"
                            result_text += f"   - åŸè¯­ä¹‰: {current_meaning or 'æœªçŸ¥'}\n"
                            result_text += f"   - æ–°è¯­ä¹‰: {correct_meaning}\n"
                            result_text += f"   - ç½®ä¿¡åº¦: {user_confidence:.2f}\n\n"
                        else:
                            failed_updates.append(field_path)
                            result_text += f"âŒ **{field_path}**: æ›´æ–°å¤±è´¥\n\n"
                            
                    except Exception as e:
                        failed_updates.append(field_path)
                        result_text += f"âŒ **{field_path}**: æ›´æ–°å¼‚å¸¸ - {str(e)}\n\n"
                        logger.error(
                            "å­—æ®µè¯­ä¹‰æ›´æ–°å¤±è´¥",
                            field_path=field_path,
                            error=str(e)
                        )
            
            # ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯
            result_text += f"### å¤„ç†ç»Ÿè®¡\n\n"
            result_text += f"- **æ›´æ–°æˆåŠŸ**: {len(updated_fields)} ä¸ªå­—æ®µ\n"
            result_text += f"- **æ›´æ–°å¤±è´¥**: {len(failed_updates)} ä¸ªå­—æ®µ\n\n"
            result_text += f"ğŸ’¡ æ›´æ–°çš„è¯­ä¹‰ä¿¡æ¯å·²è‡ªåŠ¨å­˜å‚¨åˆ°æœ€ä½³ä½ç½®ï¼ˆè¯­ä¹‰åº“æˆ–ä¸šåŠ¡åº“ï¼‰ã€‚"
            
            return [TextContent(type="text", text=result_text)]
            
        except Exception as e:
            logger.error("åé¦ˆå­¦ä¹ å¤±è´¥", error=str(e))
            return [TextContent(type="text", text=f"åé¦ˆå­¦ä¹ æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")]
    
    async def _handle_get_pending_confirmations(self, arguments: Dict[str, Any]) -> List[TextContent]:
        """å¤„ç†è·å–å¾…ç¡®è®¤é¡¹æ“ä½œ"""
        instance_id = arguments["instance_id"]
        confidence_threshold = arguments.get("confidence_threshold", 0.6)
        limit = arguments.get("limit", 20)
        
        try:
            # è·å–å¾…ç¡®è®¤çš„è¯­ä¹‰é¡¹
            pending_items = await self._get_uncertain_semantics(
                instance_id, confidence_threshold, limit
            )
            
            result_text = f"## å¾…ç¡®è®¤çš„å­—æ®µè¯­ä¹‰ ({len(pending_items)} é¡¹)\n\n"
            result_text += f"- **å®ä¾‹**: {instance_id}\n"
            result_text += f"- **ç½®ä¿¡åº¦é˜ˆå€¼**: < {confidence_threshold}\n\n"
            
            if not pending_items:
                result_text += f"ğŸ‰ æ‰€æœ‰å­—æ®µçš„è¯­ä¹‰ç½®ä¿¡åº¦éƒ½å·²è¾¾åˆ°é˜ˆå€¼è¦æ±‚ï¼\n"
                return [TextContent(type="text", text=result_text)]
            
            # æŒ‰æ•°æ®åº“å’Œé›†åˆåˆ†ç»„æ˜¾ç¤º
            grouped_items = {}
            for item in pending_items:
                db_key = f"{item['database_name']}.{item['collection_name']}"
                if db_key not in grouped_items:
                    grouped_items[db_key] = []
                grouped_items[db_key].append(item)
            
            for db_collection, items in grouped_items.items():
                result_text += f"### ğŸ“‚ {db_collection}\n\n"
                
                for i, item in enumerate(items, 1):
                    field_path = item['field_path']
                    suggested_meaning = item.get('suggested_meaning', 'æœªçŸ¥')
                    confidence = item.get('confidence', 0.0)
                    field_type = item.get('field_type', 'æœªçŸ¥')
                    
                    result_text += f"**{i}. {field_path}**\n"
                    result_text += f"   - å­—æ®µç±»å‹: {field_type}\n"
                    result_text += f"   - å»ºè®®è¯­ä¹‰: {suggested_meaning}\n"
                    result_text += f"   - ç½®ä¿¡åº¦: {confidence:.2f}\n\n"
            
            result_text += f"ğŸ’¡ å¯ä½¿ç”¨ confirm_semantics æ“ä½œè¿›è¡Œæ‰¹é‡ç¡®è®¤ã€‚"
            
            return [TextContent(type="text", text=result_text)]
            
        except Exception as e:
            logger.error("è·å–å¾…ç¡®è®¤é¡¹å¤±è´¥", error=str(e))
            return [TextContent(type="text", text=f"è·å–å¾…ç¡®è®¤é¡¹æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")]
    
    async def _handle_reject_suggestions(self, arguments: Dict[str, Any]) -> List[TextContent]:
        """å¤„ç†æ‹’ç»å»ºè®®æ“ä½œ"""
        instance_id = arguments["instance_id"]
        database_name = arguments.get("database_name")
        collection_name = arguments.get("collection_name")
        
        try:
            result_text = f"## æ‹’ç»è¯­ä¹‰å»ºè®®\n\n"
            result_text += f"- **å®ä¾‹**: {instance_id}\n"
            
            if database_name and collection_name:
                result_text += f"- **æ•°æ®åº“**: {database_name}\n"
                result_text += f"- **é›†åˆ**: {collection_name}\n\n"
                result_text += f"å·²æ ‡è®°è¯¥é›†åˆçš„è¯­ä¹‰å»ºè®®ä¸ºæ‹’ç»çŠ¶æ€ã€‚\n"
            else:
                result_text += f"\nå·²æ ‡è®°è¯¥å®ä¾‹çš„è¯­ä¹‰å»ºè®®ä¸ºæ‹’ç»çŠ¶æ€ã€‚\n"
            
            result_text += f"\nğŸ’¡ è¢«æ‹’ç»çš„å»ºè®®å°†ä¸å†å‡ºç°åœ¨å¾…ç¡®è®¤åˆ—è¡¨ä¸­ã€‚"
            
            return [TextContent(type="text", text=result_text)]
            
        except Exception as e:
            logger.error("æ‹’ç»å»ºè®®å¤±è´¥", error=str(e))
            return [TextContent(type="text", text=f"æ‹’ç»å»ºè®®æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")]
    
    # è¾…åŠ©æ–¹æ³•
    @with_error_handling("æŸ¥çœ‹å­—æ®µè¯­ä¹‰")
    async def _view_field_semantics(self, instance_id: str, database_name: str, 
                                  collection_name: str, field_path: str) -> List[TextContent]:
        """æŸ¥çœ‹ç‰¹å®šå­—æ®µçš„è¯­ä¹‰ä¿¡æ¯"""
        # ä½¿ç”¨ç»Ÿä¸€çš„æœç´¢æ–¹æ³•ï¼ˆåŒæ—¶æœç´¢è¯­ä¹‰åº“å’Œä¸šåŠ¡åº“ï¼‰
        search_results = await self.metadata_manager.search_fields_by_meaning(
            instance_id, field_path
        )
        
        # ç­›é€‰å‡ºæŒ‡å®šå­—æ®µçš„ç»“æœ
        field_results = [
            result for result in search_results
            if (result.get('database_name') == database_name and 
                result.get('collection_name') == collection_name and 
                result.get('field_path') == field_path)
        ]
        
        result_text = f"## å­—æ®µè¯­ä¹‰ä¿¡æ¯\n\n"
        result_text += f"- **å®ä¾‹**: {instance_id}\n"
        result_text += f"- **æ•°æ®åº“**: {database_name}\n"
        result_text += f"- **é›†åˆ**: {collection_name}\n"
        result_text += f"- **å­—æ®µ**: {field_path}\n\n"
        
        if field_results:
            field_info = field_results[0]
            business_meaning = field_info.get('business_meaning', 'æœªå®šä¹‰')
            field_type = field_info.get('field_type', 'æœªçŸ¥')
            semantic_source = field_info.get('semantic_source', 'æœªçŸ¥')
            examples = field_info.get('examples', [])
            
            result_text += f"### è¯­ä¹‰è¯¦æƒ…\n\n"
            result_text += f"- **å­—æ®µç±»å‹**: {field_type}\n"
            result_text += f"- **ä¸šåŠ¡å«ä¹‰**: {business_meaning}\n"
            result_text += f"- **å­˜å‚¨ä½ç½®**: {semantic_source}\n"
            
            if examples:
                examples_str = ', '.join(str(ex) for ex in examples[:5])
                result_text += f"- **ç¤ºä¾‹å€¼**: {examples_str}\n"
        else:
            result_text += f"è¯¥å­—æ®µæš‚æ— è¯­ä¹‰ä¿¡æ¯ã€‚\n"
        
        return [TextContent(type="text", text=result_text)]
    
    @with_error_handling("æŸ¥çœ‹é›†åˆè¯­ä¹‰")
    async def _view_collection_semantics(self, instance_id: str, database_name: str, collection_name: str) -> List[TextContent]:
        """æŸ¥çœ‹é›†åˆçš„æ‰€æœ‰å­—æ®µè¯­ä¹‰"""
        try:
            # è·å–å®ä¾‹ä¿¡æ¯
            instance_info = await self.metadata_manager.get_instance_by_name(instance_id, instance_id)
            if not instance_info:
                return [TextContent(
                    type="text",
                    text=f"å®ä¾‹ '{instance_id}' ä¸å­˜åœ¨"
                )]
            
            instance_obj_id = instance_info["_id"]
            
            # è·å–é›†åˆçš„æ‰€æœ‰å­—æ®µ
            fields = await self.metadata_manager.get_fields_by_collection(
                instance_id, instance_obj_id, database_name, collection_name
            )
            
            result_text = f"## é›†åˆè¯­ä¹‰è¦†ç›–æƒ…å†µ\n\n"
            result_text += f"- **å®ä¾‹**: {instance_id}\n"
            result_text += f"- **æ•°æ®åº“**: {database_name}\n"
            result_text += f"- **é›†åˆ**: {collection_name}\n"
            result_text += f"- **å­—æ®µæ€»æ•°**: {len(fields)}\n"
            
            # ç»Ÿè®¡è¯­ä¹‰è¦†ç›–æƒ…å†µ
            fields_with_semantics = [f for f in fields if f.get('business_meaning')]
            coverage_rate = len(fields_with_semantics) / len(fields) if fields else 0
            
            result_text += f"- **è¯­ä¹‰è¦†ç›–ç‡**: {coverage_rate:.1%}\n\n"
            
            if fields_with_semantics:
                result_text += f"### å·²å®šä¹‰è¯­ä¹‰çš„å­—æ®µ\n\n"
                for field in fields_with_semantics[:10]:  # æ˜¾ç¤ºå‰10ä¸ª
                    field_path = field.get('field_path', '')
                    business_meaning = field.get('business_meaning', '')
                    field_type = field.get('field_type', 'æœªçŸ¥')
                    
                    result_text += f"**{field_path}** ({field_type})\n"
                    result_text += f"- {business_meaning}\n\n"
            
            # æ˜¾ç¤ºæœªå®šä¹‰è¯­ä¹‰çš„å­—æ®µ
            fields_without_semantics = [f for f in fields if not f.get('business_meaning')]
            if fields_without_semantics:
                result_text += f"### æœªå®šä¹‰è¯­ä¹‰çš„å­—æ®µ ({len(fields_without_semantics)} ä¸ª)\n\n"
                for field in fields_without_semantics[:5]:  # æ˜¾ç¤ºå‰5ä¸ª
                    field_path = field.get('field_path', '')
                    field_type = field.get('field_type', 'æœªçŸ¥')
                    result_text += f"- **{field_path}** ({field_type})\n"
            
            return [TextContent(type="text", text=result_text)]
            
        except Exception as e:
            logger.error("æŸ¥çœ‹é›†åˆè¯­ä¹‰å¤±è´¥", error=str(e))
            return [TextContent(type="text", text=f"æŸ¥çœ‹é›†åˆè¯­ä¹‰æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")]
    
    @with_error_handling("æŸ¥çœ‹æ•°æ®åº“è¯­ä¹‰")
    async def _view_database_semantics(self, instance_id: str, database_name: str) -> List[TextContent]:
        """æŸ¥çœ‹æ•°æ®åº“çš„è¯­ä¹‰è¦†ç›–æƒ…å†µ"""
        try:
            # è·å–å®ä¾‹ä¿¡æ¯
            instance_info = await self.metadata_manager.get_instance_by_name(instance_id, instance_id)
            if not instance_info:
                return [TextContent(
                    type="text",
                    text=f"å®ä¾‹ '{instance_id}' ä¸å­˜åœ¨"
                )]
            
            instance_obj_id = instance_info["_id"]
            
            # è·å–æ•°æ®åº“çš„æ‰€æœ‰é›†åˆ
            collections = await self.metadata_manager.get_collections_by_database(
                instance_id, instance_obj_id, database_name
            )
            
            result_text = f"## æ•°æ®åº“è¯­ä¹‰è¦†ç›–æƒ…å†µ\n\n"
            result_text += f"- **å®ä¾‹**: {instance_id}\n"
            result_text += f"- **æ•°æ®åº“**: {database_name}\n"
            result_text += f"- **é›†åˆæ€»æ•°**: {len(collections)}\n\n"
            
            total_fields = 0
            total_fields_with_semantics = 0
            
            for collection in collections:
                collection_name = collection.get('collection_name', '')
                
                # è·å–é›†åˆçš„å­—æ®µ
                fields = await self.metadata_manager.get_fields_by_collection(
                    instance_id, instance_obj_id, database_name, collection_name
                )
                
                fields_with_semantics = [f for f in fields if f.get('business_meaning')]
                
                total_fields += len(fields)
                total_fields_with_semantics += len(fields_with_semantics)
                
                coverage_rate = len(fields_with_semantics) / len(fields) if fields else 0
                
                result_text += f"### ğŸ“‚ {collection_name}\n"
                result_text += f"- å­—æ®µæ•°: {len(fields)}\n"
                result_text += f"- è¯­ä¹‰è¦†ç›–ç‡: {coverage_rate:.1%}\n\n"
            
            # æ€»ä½“ç»Ÿè®¡
            overall_coverage = total_fields_with_semantics / total_fields if total_fields else 0
            result_text += f"### ğŸ“Š æ€»ä½“ç»Ÿè®¡\n\n"
            result_text += f"- **æ€»å­—æ®µæ•°**: {total_fields}\n"
            result_text += f"- **å·²å®šä¹‰è¯­ä¹‰**: {total_fields_with_semantics}\n"
            result_text += f"- **æ•´ä½“è¦†ç›–ç‡**: {overall_coverage:.1%}\n"
            
            return [TextContent(type="text", text=result_text)]
            
        except Exception as e:
            logger.error("æŸ¥çœ‹æ•°æ®åº“è¯­ä¹‰å¤±è´¥", error=str(e))
            return [TextContent(type="text", text=f"æŸ¥çœ‹æ•°æ®åº“è¯­ä¹‰æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")]
    
    @with_error_handling("æŸ¥çœ‹å®ä¾‹è¯­ä¹‰")
    async def _view_instance_semantics(self, instance_id: str) -> List[TextContent]:
        """æŸ¥çœ‹å®ä¾‹çš„è¯­ä¹‰è¦†ç›–æƒ…å†µ"""
        try:
            # è·å–å®ä¾‹ä¿¡æ¯
            instance_info = await self.metadata_manager.get_instance_by_name(instance_id, instance_id)
            if not instance_info:
                return [TextContent(
                    type="text",
                    text=f"å®ä¾‹ '{instance_id}' ä¸å­˜åœ¨"
                )]
            
            instance_obj_id = instance_info["_id"]
            
            # è·å–å®ä¾‹çš„æ‰€æœ‰æ•°æ®åº“
            databases = await self.metadata_manager.get_databases_by_instance(
                instance_id, instance_obj_id
            )
            
            result_text = f"## å®ä¾‹è¯­ä¹‰è¦†ç›–æƒ…å†µ\n\n"
            result_text += f"- **å®ä¾‹**: {instance_id}\n"
            result_text += f"- **æ•°æ®åº“æ€»æ•°**: {len(databases)}\n\n"
            
            total_collections = 0
            total_fields = 0
            total_fields_with_semantics = 0
            
            for database in databases:
                database_name = database.get('database_name', '')
                
                # è·å–æ•°æ®åº“çš„é›†åˆ
                collections = await self.metadata_manager.get_collections_by_database(
                    instance_id, instance_obj_id, database_name
                )
                
                total_collections += len(collections)
                
                db_fields = 0
                db_fields_with_semantics = 0
                
                for collection in collections:
                    collection_name = collection.get('collection_name', '')
                    
                    # è·å–é›†åˆçš„å­—æ®µ
                    fields = await self.metadata_manager.get_fields_by_collection(
                        instance_id, instance_obj_id, database_name, collection_name
                    )
                    
                    fields_with_semantics = [f for f in fields if f.get('business_meaning')]
                    
                    db_fields += len(fields)
                    db_fields_with_semantics += len(fields_with_semantics)
                
                total_fields += db_fields
                total_fields_with_semantics += db_fields_with_semantics
                
                coverage_rate = db_fields_with_semantics / db_fields if db_fields else 0
                
                result_text += f"### ğŸ“‚ {database_name}\n"
                result_text += f"- é›†åˆæ•°: {len(collections)}\n"
                result_text += f"- å­—æ®µæ•°: {db_fields}\n"
                result_text += f"- è¯­ä¹‰è¦†ç›–ç‡: {coverage_rate:.1%}\n\n"
            
            # æ€»ä½“ç»Ÿè®¡
            overall_coverage = total_fields_with_semantics / total_fields if total_fields else 0
            result_text += f"### ğŸ“Š æ€»ä½“ç»Ÿè®¡\n\n"
            result_text += f"- **æ€»é›†åˆæ•°**: {total_collections}\n"
            result_text += f"- **æ€»å­—æ®µæ•°**: {total_fields}\n"
            result_text += f"- **å·²å®šä¹‰è¯­ä¹‰**: {total_fields_with_semantics}\n"
            result_text += f"- **æ•´ä½“è¦†ç›–ç‡**: {overall_coverage:.1%}\n\n"
            result_text += f"ğŸ’¡ è¯­ä¹‰ä¿¡æ¯æ¥è‡ªè¯­ä¹‰åº“å’Œä¸šåŠ¡åº“çš„ç»¼åˆç»Ÿè®¡ã€‚"
            
            return [TextContent(type="text", text=result_text)]
            
        except Exception as e:
            logger.error("æŸ¥çœ‹å®ä¾‹è¯­ä¹‰å¤±è´¥", error=str(e))
            return [TextContent(type="text", text=f"æŸ¥çœ‹å®ä¾‹è¯­ä¹‰æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")]
    
    async def _get_uncertain_semantics(self, instance_id: str, 
                                     confidence_threshold: float = 0.6,
                                     limit: int = 20) -> List[Dict[str, Any]]:
        """è·å–ç½®ä¿¡åº¦ä½äºé˜ˆå€¼çš„è¯­ä¹‰é¡¹"""
        try:
            # è¿™é‡Œéœ€è¦å®ç°è·å–ä¸ç¡®å®šè¯­ä¹‰çš„é€»è¾‘
            # æš‚æ—¶è¿”å›ç©ºåˆ—è¡¨ï¼Œå®é™…å®ç°éœ€è¦æŸ¥è¯¢å…ƒæ•°æ®åº“å’Œä¸šåŠ¡åº“
            return []
            
        except Exception as e:
            logger.error("è·å–ä¸ç¡®å®šè¯­ä¹‰å¤±è´¥", error=str(e))
            return []