# -*- coding: utf-8 -*-
"""è¯­ä¹‰ç®¡ç†å·¥å…·"""

from typing import Dict, List, Any, Optional
import structlog
from mcp.types import Tool, TextContent

from database.connection_manager import ConnectionManager
from database.metadata_manager import MetadataManager
from scanner.semantic_analyzer import SemanticAnalyzer


logger = structlog.get_logger(__name__)


class SemanticManagementTool:
    """è¯­ä¹‰ç®¡ç†å·¥å…·"""
    
    def __init__(self, connection_manager: ConnectionManager, 
                 metadata_manager: MetadataManager,
                 semantic_analyzer: SemanticAnalyzer):
        self.connection_manager = connection_manager
        self.metadata_manager = metadata_manager
        self.semantic_analyzer = semantic_analyzer
    
    def get_tool_definition(self) -> Tool:
        """è·å–å·¥å…·å®šä¹‰"""
        return Tool(
            name="manage_semantics",
            description="ç®¡ç†å­—æ®µçš„ä¸šåŠ¡è¯­ä¹‰ä¿¡æ¯ï¼ŒåŒ…æ‹¬æŸ¥çœ‹ã€æ›´æ–°å’Œæ‰¹é‡åˆ†æ",
            inputSchema={
                "type": "object",
                "properties": {
                    "action": {
                        "type": "string",
                        "enum": ["view", "update", "batch_analyze", "search", "suggest"],
                        "description": "æ“ä½œç±»å‹ï¼šview(æŸ¥çœ‹), update(æ›´æ–°), batch_analyze(æ‰¹é‡åˆ†æ), search(æœç´¢), suggest(å»ºè®®)"
                    },
                    "instance_id": {
                        "type": "string",
                        "description": "MongoDBå®ä¾‹ID"
                    },
                    "database_name": {
                        "type": "string",
                        "description": "æ•°æ®åº“åç§°"
                    },
                    "collection_name": {
                        "type": "string",
                        "description": "é›†åˆåç§°"
                    },
                    "field_path": {
                        "type": "string",
                        "description": "å­—æ®µè·¯å¾„ï¼ˆç”¨äºviewå’Œupdateæ“ä½œï¼‰"
                    },
                    "business_meaning": {
                        "type": "string",
                        "description": "ä¸šåŠ¡å«ä¹‰ï¼ˆç”¨äºupdateæ“ä½œï¼‰"
                    },
                    "search_term": {
                        "type": "string",
                        "description": "æœç´¢å…³é”®è¯ï¼ˆç”¨äºsearchæ“ä½œï¼‰"
                    },
                    "query_description": {
                        "type": "string",
                        "description": "æŸ¥è¯¢æè¿°ï¼ˆç”¨äºsuggestæ“ä½œï¼‰"
                    }
                },
                "required": ["action", "instance_id"]
            }
        )
    
    async def execute(self, arguments: Dict[str, Any]) -> List[TextContent]:
        """æ‰§è¡Œè¯­ä¹‰ç®¡ç†æ“ä½œ"""
        action = arguments["action"]
        instance_id = arguments["instance_id"]
        
        logger.info("æ‰§è¡Œè¯­ä¹‰ç®¡ç†æ“ä½œ", action=action, instance_id=instance_id)
        
        try:
            # éªŒè¯å®ä¾‹
            if not self.connection_manager.has_instance(instance_id):
                return [TextContent(
                    type="text",
                    text=f"å®ä¾‹ '{instance_id}' ä¸å­˜åœ¨ã€‚è¯·ä½¿ç”¨ discover_instances å·¥å…·æŸ¥çœ‹å¯ç”¨å®ä¾‹ã€‚"
                )]
            
            # æ ¹æ®æ“ä½œç±»å‹æ‰§è¡Œç›¸åº”åŠŸèƒ½
            if action == "view":
                return await self._handle_view(arguments)
            elif action == "update":
                return await self._handle_update(arguments)
            elif action == "batch_analyze":
                return await self._handle_batch_analyze(arguments)
            elif action == "search":
                return await self._handle_search(arguments)
            elif action == "suggest":
                return await self._handle_suggest(arguments)
            else:
                return [TextContent(
                    type="text",
                    text=f"ä¸æ”¯æŒçš„æ“ä½œç±»å‹: {action}"
                )]
                
        except Exception as e:
            error_msg = f"æ‰§è¡Œè¯­ä¹‰ç®¡ç†æ“ä½œæ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"
            logger.error("è¯­ä¹‰ç®¡ç†æ“ä½œå¤±è´¥", action=action, instance_id=instance_id, error=str(e))
            return [TextContent(type="text", text=error_msg)]
    
    async def _handle_view(self, arguments: Dict[str, Any]) -> List[TextContent]:
        """å¤„ç†æŸ¥çœ‹æ“ä½œ"""
        instance_id = arguments["instance_id"]
        database_name = arguments.get("database_name")
        collection_name = arguments.get("collection_name")
        field_path = arguments.get("field_path")
        
        if field_path and database_name and collection_name:
            # æŸ¥çœ‹ç‰¹å®šå­—æ®µçš„è¯­ä¹‰ä¿¡æ¯
            return await self._view_field_semantics(instance_id, database_name, collection_name, field_path)
        elif database_name and collection_name:
            # æŸ¥çœ‹é›†åˆçš„æ‰€æœ‰å­—æ®µè¯­ä¹‰
            return await self._view_collection_semantics(instance_id, database_name, collection_name)
        elif database_name:
            # æŸ¥çœ‹æ•°æ®åº“çš„è¯­ä¹‰è¦†ç›–æƒ…å†µ
            return await self._view_database_semantics(instance_id, database_name)
        else:
            # æŸ¥çœ‹å®ä¾‹çš„è¯­ä¹‰è¦†ç›–æƒ…å†µ
            return await self._view_instance_semantics(instance_id)
    
    async def _handle_update(self, arguments: Dict[str, Any]) -> List[TextContent]:
        """å¤„ç†æ›´æ–°æ“ä½œ"""
        instance_id = arguments["instance_id"]
        database_name = arguments.get("database_name")
        collection_name = arguments.get("collection_name")
        field_path = arguments.get("field_path")
        business_meaning = arguments.get("business_meaning")
        
        if not all([database_name, collection_name, field_path, business_meaning]):
            return [TextContent(
                type="text",
                text="æ›´æ–°æ“ä½œéœ€è¦æä¾› database_name, collection_name, field_path å’Œ business_meaning å‚æ•°ã€‚"
            )]
        
        try:
            # æ›´æ–°å­—æ®µè¯­ä¹‰ - éœ€è¦ä¼ å…¥æ­£ç¡®çš„å‚æ•°
            # ç”±äºæ–°çš„åŒé‡å­˜å‚¨ç­–ç•¥ï¼Œéœ€è¦æä¾›instance_idä½œä¸ºObjectId
            from bson import ObjectId
            try:
                # å¦‚æœinstance_idæ˜¯å­—ç¬¦ä¸²ï¼Œéœ€è¦è½¬æ¢æˆ–ä½¿ç”¨å®ä¾‹åç§°
                success = await self.metadata_manager.update_field_semantics(
                    instance_id, ObjectId(), database_name, collection_name, field_path, business_meaning
                )
            except:
                # å¦‚æœObjectIdè½¬æ¢å¤±è´¥ï¼Œä½¿ç”¨å®ä¾‹åç§°çš„æ–¹å¼è°ƒç”¨æ–°ç‰ˆæœ¬æ–¹æ³•
                success = await self._update_field_semantics_by_instance_name(
                    instance_id, database_name, collection_name, field_path, business_meaning
                )
            
            if success:
                result_text = f"âœ… æˆåŠŸæ›´æ–°å­—æ®µè¯­ä¹‰\n\n"
                result_text += f"- **å®ä¾‹**: {instance_id}\n"
                result_text += f"- **æ•°æ®åº“**: {database_name}\n"
                result_text += f"- **é›†åˆ**: {collection_name}\n"
                result_text += f"- **å­—æ®µ**: {field_path}\n"
                result_text += f"- **ä¸šåŠ¡å«ä¹‰**: {business_meaning}\n"
                
                logger.info(
                    "å­—æ®µè¯­ä¹‰æ›´æ–°æˆåŠŸ",
                    instance_id=instance_id,
                    database=database_name,
                    collection=collection_name,
                    field_path=field_path
                )
            else:
                result_text = f"âŒ æ›´æ–°å­—æ®µè¯­ä¹‰å¤±è´¥\n\n"
                result_text += f"è¯·æ£€æŸ¥å­—æ®µè·¯å¾„æ˜¯å¦æ­£ç¡®ï¼Œæˆ–å­—æ®µæ˜¯å¦å­˜åœ¨äºé›†åˆä¸­ã€‚"
            
            return [TextContent(type="text", text=result_text)]
            
        except Exception as e:
            logger.error("æ›´æ–°å­—æ®µè¯­ä¹‰å¤±è´¥", error=str(e))
            return [TextContent(type="text", text=f"æ›´æ–°å­—æ®µè¯­ä¹‰æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")]
    
    async def _handle_batch_analyze(self, arguments: Dict[str, Any]) -> List[TextContent]:
        """å¤„ç†æ‰¹é‡åˆ†ææ“ä½œ"""
        instance_id = arguments["instance_id"]
        database_name = arguments.get("database_name")
        collection_name = arguments.get("collection_name")
        
        if not all([database_name, collection_name]):
            return [TextContent(
                type="text",
                text="æ‰¹é‡åˆ†ææ“ä½œéœ€è¦æä¾› database_name å’Œ collection_name å‚æ•°ã€‚"
            )]
        
        try:
            # æ‰§è¡Œæ‰¹é‡è¯­ä¹‰åˆ†æ
            analysis_result = await self.semantic_analyzer.batch_analyze_collection(
                instance_id, database_name, collection_name
            )
            
            result_text = f"## æ‰¹é‡è¯­ä¹‰åˆ†æç»“æœ: {database_name}.{collection_name}\n\n"
            
            if "error" in analysis_result:
                result_text += f"âŒ åˆ†æå¤±è´¥: {analysis_result['error']}\n"
                return [TextContent(type="text", text=result_text)]
            
            total_fields = analysis_result["total_fields"]
            analyzed_fields = analysis_result["analyzed_fields"]
            updated_fields = analysis_result["updated_fields"]
            
            result_text += f"### åˆ†æç»Ÿè®¡\n\n"
            result_text += f"- **å­—æ®µæ€»æ•°**: {total_fields}\n"
            result_text += f"- **åˆ†æå­—æ®µæ•°**: {analyzed_fields}\n"
            result_text += f"- **è‡ªåŠ¨æ›´æ–°æ•°**: {updated_fields}\n"
            
            if analyzed_fields > 0:
                auto_update_rate = updated_fields / analyzed_fields
                result_text += f"- **è‡ªåŠ¨æ›´æ–°ç‡**: {auto_update_rate:.1%}\n"
            
            result_text += "\n"
            
            # æ˜¾ç¤ºåˆ†æç»“æœè¯¦æƒ…
            analysis_results = analysis_result.get("analysis_results", {})
            if analysis_results:
                result_text += "### åˆ†æè¯¦æƒ…\n\n"
                
                for field_path, analysis in analysis_results.items():
                    suggested_meaning = analysis["suggested_meaning"]
                    confidence = analysis["confidence"]
                    
                    result_text += f"#### {field_path}\n"
                    result_text += f"- **å»ºè®®å«ä¹‰**: {suggested_meaning}\n"
                    result_text += f"- **ç½®ä¿¡åº¦**: {confidence:.1%}\n"
                    
                    if analysis["reasoning"]:
                        result_text += f"- **æ¨ç†ä¾æ®**: {', '.join(analysis['reasoning'])}\n"
                    
                    if analysis["suggestions"]:
                        result_text += f"- **æ”¹è¿›å»ºè®®**: {'; '.join(analysis['suggestions'])}\n"
                    
                    result_text += "\n"
            
            # æ·»åŠ åç»­æ“ä½œå»ºè®®
            result_text += "### åç»­æ“ä½œå»ºè®®\n\n"
            if updated_fields < analyzed_fields:
                result_text += "- å¯¹äºç½®ä¿¡åº¦è¾ƒä½çš„å­—æ®µï¼Œå»ºè®®æ‰‹åŠ¨ç¡®è®¤å’Œæ›´æ–°è¯­ä¹‰ä¿¡æ¯\n"
            result_text += "- ä½¿ç”¨ `manage_semantics` çš„ view æ“ä½œæŸ¥çœ‹æ›´æ–°åçš„è¯­ä¹‰ä¿¡æ¯\n"
            result_text += "- ä½¿ç”¨ `generate_query` å·¥å…·æµ‹è¯•è¯­ä¹‰ç†è§£æ•ˆæœ\n"
            
            logger.info(
                "æ‰¹é‡è¯­ä¹‰åˆ†æå®Œæˆ",
                instance_id=instance_id,
                database=database_name,
                collection=collection_name,
                total_fields=total_fields,
                updated_fields=updated_fields
            )
            
            return [TextContent(type="text", text=result_text)]
            
        except Exception as e:
            logger.error("æ‰¹é‡è¯­ä¹‰åˆ†æå¤±è´¥", error=str(e))
            return [TextContent(type="text", text=f"æ‰¹é‡è¯­ä¹‰åˆ†ææ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")]
    
    async def _handle_search(self, arguments: Dict[str, Any]) -> List[TextContent]:
        """å¤„ç†æœç´¢æ“ä½œ"""
        instance_id = arguments["instance_id"]
        search_term = arguments.get("search_term")
        
        if not search_term:
            return [TextContent(
                type="text",
                text="æœç´¢æ“ä½œéœ€è¦æä¾› search_term å‚æ•°ã€‚"
            )]
        
        try:
            # æœç´¢ç›¸å…³å­—æ®µ
            search_results = await self.metadata_manager.search_fields_by_meaning(
                instance_id, search_term
            )
            
            if not search_results:
                return [TextContent(
                    type="text",
                    text=f"æœªæ‰¾åˆ°ä¸ '{search_term}' ç›¸å…³çš„å­—æ®µã€‚"
                )]
            
            result_text = f"## è¯­ä¹‰æœç´¢ç»“æœ: '{search_term}'\n\n"
            
            # æŒ‰æ•°æ®åº“å’Œé›†åˆåˆ†ç»„æ˜¾ç¤ºç»“æœ
            grouped_results = {}
            for field in search_results:
                db_name = field["database_name"]
                coll_name = field["collection_name"]
                key = f"{db_name}.{coll_name}"
                
                if key not in grouped_results:
                    grouped_results[key] = []
                grouped_results[key].append(field)
            
            for collection_key, fields in grouped_results.items():
                result_text += f"### {collection_key}\n\n"
                
                for field in fields:
                    field_path = field["field_path"]
                    business_meaning = field.get("business_meaning", "æœªå®šä¹‰")
                    field_type = field.get("field_type", "unknown")
                    
                    result_text += f"- **{field_path}** ({field_type})\n"
                    result_text += f"  - ä¸šåŠ¡å«ä¹‰: {business_meaning}\n"
                    
                    if field.get("examples"):
                        examples = field["examples"][:2]
                        examples_str = ", ".join([str(ex) for ex in examples])
                        result_text += f"  - ç¤ºä¾‹å€¼: {examples_str}\n"
                
                result_text += "\n"
            
            result_text += f"### æœç´¢ç»Ÿè®¡\n\n"
            result_text += f"- **åŒ¹é…å­—æ®µæ•°**: {len(search_results)}\n"
            result_text += f"- **æ¶‰åŠé›†åˆæ•°**: {len(grouped_results)}\n"
            
            return [TextContent(type="text", text=result_text)]
            
        except Exception as e:
            logger.error("è¯­ä¹‰æœç´¢å¤±è´¥", error=str(e))
            return [TextContent(type="text", text=f"è¯­ä¹‰æœç´¢æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")]
    
    async def _handle_suggest(self, arguments: Dict[str, Any]) -> List[TextContent]:
        """å¤„ç†å»ºè®®æ“ä½œ"""
        instance_id = arguments["instance_id"]
        database_name = arguments.get("database_name")
        collection_name = arguments.get("collection_name")
        query_description = arguments.get("query_description")
        
        if not all([database_name, collection_name, query_description]):
            return [TextContent(
                type="text",
                text="å»ºè®®æ“ä½œéœ€è¦æä¾› database_name, collection_name å’Œ query_description å‚æ•°ã€‚"
            )]
        
        try:
            # è·å–å­—æ®µå»ºè®®
            from .collection_analysis import CollectionAnalysisTool
            
            analysis_tool = CollectionAnalysisTool(
                self.connection_manager, self.metadata_manager, self.semantic_analyzer
            )
            
            suggestions = await analysis_tool.get_field_suggestions(
                instance_id, database_name, collection_name, query_description
            )
            
            if not suggestions:
                return [TextContent(
                    type="text",
                    text=f"æœªæ‰¾åˆ°ä¸æŸ¥è¯¢æè¿° '{query_description}' ç›¸å…³çš„å­—æ®µå»ºè®®ã€‚"
                )]
            
            result_text = f"## å­—æ®µå»ºè®®: '{query_description}'\n\n"
            result_text += f"åŸºäºæŸ¥è¯¢æè¿°ï¼Œä¸ºé›†åˆ `{database_name}.{collection_name}` æ¨èä»¥ä¸‹å­—æ®µ:\n\n"
            
            for i, suggestion in enumerate(suggestions[:10], 1):
                field_path = suggestion["field_path"]
                business_meaning = suggestion["business_meaning"] or "æœªå®šä¹‰"
                relevance_score = suggestion["relevance_score"]
                field_type = suggestion["field_type"]
                
                result_text += f"{i}. **{field_path}** ({field_type})\n"
                result_text += f"   - ä¸šåŠ¡å«ä¹‰: {business_meaning}\n"
                result_text += f"   - ç›¸å…³æ€§: {relevance_score:.1%}\n\n"
            
            result_text += "### ä½¿ç”¨å»ºè®®\n\n"
            result_text += "- é€‰æ‹©ç›¸å…³æ€§é«˜çš„å­—æ®µæ„å»ºæŸ¥è¯¢æ¡ä»¶\n"
            result_text += "- ä½¿ç”¨ `generate_query` å·¥å…·ç”Ÿæˆå…·ä½“çš„æŸ¥è¯¢è¯­å¥\n"
            result_text += "- å¦‚æœå­—æ®µå«ä¹‰ä¸æ˜ç¡®ï¼Œä½¿ç”¨ `manage_semantics` å·¥å…·æ›´æ–°è¯­ä¹‰ä¿¡æ¯\n"
            
            return [TextContent(type="text", text=result_text)]
            
        except Exception as e:
            logger.error("è·å–å­—æ®µå»ºè®®å¤±è´¥", error=str(e))
            return [TextContent(type="text", text=f"è·å–å­—æ®µå»ºè®®æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")]
    
    async def _view_field_semantics(self, instance_id: str, database_name: str, 
                                  collection_name: str, field_path: str) -> List[TextContent]:
        """æŸ¥çœ‹ç‰¹å®šå­—æ®µçš„è¯­ä¹‰ä¿¡æ¯"""
        try:
            field_info = await self.metadata_manager.get_field_info(
                instance_id, database_name, collection_name, field_path
            )
            
            if not field_info:
                return [TextContent(
                    type="text",
                    text=f"å­—æ®µ '{field_path}' ä¸å­˜åœ¨äºé›†åˆ '{database_name}.{collection_name}' ä¸­ã€‚"
                )]
            
            result_text = f"## å­—æ®µè¯­ä¹‰ä¿¡æ¯: {field_path}\n\n"
            result_text += f"- **å®ä¾‹**: {instance_id}\n"
            result_text += f"- **æ•°æ®åº“**: {database_name}\n"
            result_text += f"- **é›†åˆ**: {collection_name}\n"
            result_text += f"- **å­—æ®µè·¯å¾„**: {field_path}\n"
            result_text += f"- **æ•°æ®ç±»å‹**: {field_info.get('field_type', 'unknown')}\n"
            result_text += f"- **å‡ºç°ç‡**: {field_info.get('occurrence_rate', 0):.1%}\n"
            
            business_meaning = field_info.get("business_meaning")
            if business_meaning:
                result_text += f"- **ä¸šåŠ¡å«ä¹‰**: {business_meaning}\n"
            else:
                result_text += f"- **ä¸šåŠ¡å«ä¹‰**: æœªå®šä¹‰\n"
                
                # æä¾›è¯­ä¹‰å»ºè®®
                analysis = await self.semantic_analyzer.analyze_field_semantics(
                    instance_id, database_name, collection_name, field_path, field_info
                )
                if analysis["suggested_meaning"]:
                    result_text += f"- **å»ºè®®å«ä¹‰**: {analysis['suggested_meaning']} (ç½®ä¿¡åº¦: {analysis['confidence']:.1%})\n"
            
            if field_info.get("examples"):
                examples = field_info["examples"][:5]
                examples_str = ", ".join([str(ex) for ex in examples])
                result_text += f"- **ç¤ºä¾‹å€¼**: {examples_str}\n"
            
            if field_info.get("is_indexed"):
                result_text += f"- **ç´¢å¼•çŠ¶æ€**: âœ… å·²ç´¢å¼•\n"
            
            if field_info.get("is_required"):
                result_text += f"- **å¿…éœ€å­—æ®µ**: âœ… æ˜¯\n"
            
            return [TextContent(type="text", text=result_text)]
            
        except Exception as e:
            logger.error("æŸ¥çœ‹å­—æ®µè¯­ä¹‰å¤±è´¥", error=str(e))
            return [TextContent(type="text", text=f"æŸ¥çœ‹å­—æ®µè¯­ä¹‰æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")]
    
    async def _view_collection_semantics(self, instance_id: str, database_name: str, collection_name: str) -> List[TextContent]:
        """æŸ¥çœ‹é›†åˆçš„è¯­ä¹‰è¦†ç›–æƒ…å†µ"""
        try:
            fields = await self.metadata_manager.get_fields_by_collection(
                instance_id, instance_id, database_name, collection_name
            )
            
            if not fields:
                return [TextContent(
                    type="text",
                    text=f"é›†åˆ '{database_name}.{collection_name}' ä¸­æ²¡æœ‰å­—æ®µä¿¡æ¯ã€‚è¯·å…ˆä½¿ç”¨ analyze_collection å·¥å…·æ‰«æé›†åˆç»“æ„ã€‚"
                )]
            
            total_fields = len(fields)
            fields_with_meaning = sum(1 for field in fields if field.get("business_meaning"))
            coverage_rate = fields_with_meaning / total_fields if total_fields > 0 else 0
            
            result_text = f"## é›†åˆè¯­ä¹‰è¦†ç›–: {database_name}.{collection_name}\n\n"
            result_text += f"### ç»Ÿè®¡ä¿¡æ¯\n\n"
            result_text += f"- **å­—æ®µæ€»æ•°**: {total_fields}\n"
            result_text += f"- **å·²å®šä¹‰è¯­ä¹‰**: {fields_with_meaning}\n"
            result_text += f"- **è¦†ç›–ç‡**: {coverage_rate:.1%}\n\n"
            
            # æ˜¾ç¤ºå·²å®šä¹‰è¯­ä¹‰çš„å­—æ®µ
            fields_with_semantics = [f for f in fields if f.get("business_meaning")]
            if fields_with_semantics:
                result_text += f"### å·²å®šä¹‰è¯­ä¹‰çš„å­—æ®µ\n\n"
                for field in fields_with_semantics:
                    field_path = field["field_path"]
                    business_meaning = field["business_meaning"]
                    result_text += f"- **{field_path}**: {business_meaning}\n"
                result_text += "\n"
            
            # æ˜¾ç¤ºæœªå®šä¹‰è¯­ä¹‰çš„å­—æ®µ
            fields_without_semantics = [f for f in fields if not f.get("business_meaning")]
            if fields_without_semantics:
                result_text += f"### æœªå®šä¹‰è¯­ä¹‰çš„å­—æ®µ\n\n"
                for field in fields_without_semantics[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
                    field_path = field["field_path"]
                    field_type = field.get("field_type", "unknown")
                    result_text += f"- **{field_path}** ({field_type})\n"
                
                if len(fields_without_semantics) > 10:
                    result_text += f"- ... è¿˜æœ‰ {len(fields_without_semantics) - 10} ä¸ªå­—æ®µ\n"
                
                result_text += "\n"
                result_text += "ğŸ’¡ **å»ºè®®**: ä½¿ç”¨ `manage_semantics` çš„ batch_analyze æ“ä½œè‡ªåŠ¨åˆ†æè¿™äº›å­—æ®µçš„è¯­ä¹‰\n\n"
            
            return [TextContent(type="text", text=result_text)]
            
        except Exception as e:
            logger.error("æŸ¥çœ‹é›†åˆè¯­ä¹‰å¤±è´¥", error=str(e))
            return [TextContent(type="text", text=f"æŸ¥çœ‹é›†åˆè¯­ä¹‰æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")]
    
    async def _view_database_semantics(self, instance_id: str, database_name: str) -> List[TextContent]:
        """æŸ¥çœ‹æ•°æ®åº“çš„è¯­ä¹‰è¦†ç›–æƒ…å†µ"""
        try:
            # è·å–æ•°æ®åº“ä¸­çš„æ‰€æœ‰é›†åˆ
            collections = await self.metadata_manager.get_collections_by_database(instance_id, database_name)
            
            if not collections:
                return [TextContent(
                    type="text",
                    text=f"æ•°æ®åº“ '{database_name}' ä¸­æ²¡æœ‰é›†åˆä¿¡æ¯ã€‚è¯·å…ˆä½¿ç”¨ç›¸å…³å·¥å…·æ‰«ææ•°æ®åº“ç»“æ„ã€‚"
                )]
            
            result_text = f"## æ•°æ®åº“è¯­ä¹‰è¦†ç›–: {database_name}\n\n"
            
            total_collections = len(collections)
            total_fields = 0
            total_fields_with_meaning = 0
            
            collection_stats = []
            
            for collection in collections:
                collection_name = collection["collection_name"]
                fields = await self.metadata_manager.get_fields_by_collection(
                    instance_id, database_name, collection_name
                )
                
                field_count = len(fields)
                fields_with_meaning = sum(1 for field in fields if field.get("business_meaning"))
                coverage_rate = fields_with_meaning / field_count if field_count > 0 else 0
                
                collection_stats.append({
                    "collection_name": collection_name,
                    "field_count": field_count,
                    "fields_with_meaning": fields_with_meaning,
                    "coverage_rate": coverage_rate
                })
                
                total_fields += field_count
                total_fields_with_meaning += fields_with_meaning
            
            overall_coverage = total_fields_with_meaning / total_fields if total_fields > 0 else 0
            
            result_text += f"### æ€»ä½“ç»Ÿè®¡\n\n"
            result_text += f"- **é›†åˆæ•°é‡**: {total_collections}\n"
            result_text += f"- **å­—æ®µæ€»æ•°**: {total_fields}\n"
            result_text += f"- **å·²å®šä¹‰è¯­ä¹‰**: {total_fields_with_meaning}\n"
            result_text += f"- **æ•´ä½“è¦†ç›–ç‡**: {overall_coverage:.1%}\n\n"
            
            result_text += f"### å„é›†åˆè¦†ç›–æƒ…å†µ\n\n"
            for stats in collection_stats:
                collection_name = stats["collection_name"]
                field_count = stats["field_count"]
                fields_with_meaning = stats["fields_with_meaning"]
                coverage_rate = stats["coverage_rate"]
                
                status_icon = "âœ…" if coverage_rate > 0.8 else "âš ï¸" if coverage_rate > 0.5 else "âŒ"
                
                result_text += f"- {status_icon} **{collection_name}**: {fields_with_meaning}/{field_count} ({coverage_rate:.1%})\n"
            
            result_text += "\n"
            
            # æä¾›æ”¹è¿›å»ºè®®
            low_coverage_collections = [s for s in collection_stats if s["coverage_rate"] < 0.5]
            if low_coverage_collections:
                result_text += f"### æ”¹è¿›å»ºè®®\n\n"
                result_text += f"ä»¥ä¸‹é›†åˆçš„è¯­ä¹‰è¦†ç›–ç‡è¾ƒä½ï¼Œå»ºè®®ä¼˜å…ˆå¤„ç†:\n\n"
                for stats in low_coverage_collections[:5]:
                    result_text += f"- {stats['collection_name']} ({stats['coverage_rate']:.1%})\n"
                result_text += "\nä½¿ç”¨ `manage_semantics` çš„ batch_analyze æ“ä½œå¯ä»¥è‡ªåŠ¨åˆ†æè¿™äº›é›†åˆçš„å­—æ®µè¯­ä¹‰ã€‚\n\n"
            
            return [TextContent(type="text", text=result_text)]
            
        except Exception as e:
            logger.error("æŸ¥çœ‹æ•°æ®åº“è¯­ä¹‰å¤±è´¥", error=str(e))
            return [TextContent(type="text", text=f"æŸ¥çœ‹æ•°æ®åº“è¯­ä¹‰æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")]
    
    async def _view_instance_semantics(self, instance_id: str) -> List[TextContent]:
        """æŸ¥çœ‹å®ä¾‹çš„è¯­ä¹‰è¦†ç›–æƒ…å†µ"""
        try:
            # è·å–å®ä¾‹ç»Ÿè®¡ä¿¡æ¯
            stats = await self.metadata_manager.get_instance_stats(instance_id)
            
            if not stats:
                return [TextContent(
                    type="text",
                    text=f"å®ä¾‹ '{instance_id}' æ²¡æœ‰ç»Ÿè®¡ä¿¡æ¯ã€‚è¯·å…ˆæ‰«æå®ä¾‹ç»“æ„ã€‚"
                )]
            
            result_text = f"## å®ä¾‹è¯­ä¹‰è¦†ç›–: {instance_id}\n\n"
            result_text += f"### ç»Ÿè®¡ä¿¡æ¯\n\n"
            result_text += f"- **æ•°æ®åº“æ•°é‡**: {stats.get('database_count', 0)}\n"
            result_text += f"- **é›†åˆæ•°é‡**: {stats.get('collection_count', 0)}\n"
            result_text += f"- **å­—æ®µæ€»æ•°**: {stats.get('field_count', 0)}\n"
            result_text += f"- **å·²å®šä¹‰è¯­ä¹‰**: {stats.get('fields_with_meaning', 0)}\n"
            
            field_count = stats.get('field_count', 0)
            fields_with_meaning = stats.get('fields_with_meaning', 0)
            if field_count > 0:
                coverage_rate = fields_with_meaning / field_count
                result_text += f"- **æ•´ä½“è¦†ç›–ç‡**: {coverage_rate:.1%}\n"
            
            result_text += "\n"
            result_text += "ğŸ’¡ **æç¤º**: ä½¿ç”¨ `manage_semantics` çš„ view æ“ä½œæŸ¥çœ‹ç‰¹å®šæ•°æ®åº“æˆ–é›†åˆçš„è¯¦ç»†è¯­ä¹‰ä¿¡æ¯ã€‚\n"
            
            return [TextContent(type="text", text=result_text)]
            
        except Exception as e:
            logger.error("æŸ¥çœ‹å®ä¾‹è¯­ä¹‰å¤±è´¥", error=str(e))
            return [TextContent(type="text", text=f"æŸ¥çœ‹å®ä¾‹è¯­ä¹‰æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")]
    
    async def _update_field_semantics_by_instance_name(self, instance_name: str, database_name: str, 
                                                     collection_name: str, field_path: str, 
                                                     business_meaning: str) -> bool:
        """ä½¿ç”¨å®ä¾‹åç§°æ›´æ–°å­—æ®µè¯­ä¹‰çš„è¾…åŠ©æ–¹æ³•"""
        try:
            # ç›´æ¥è°ƒç”¨æ–°çš„åŒé‡å­˜å‚¨ç­–ç•¥æ–¹æ³•
            # è¿™é‡Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ªå‡çš„ObjectIdï¼Œå› ä¸ºæ–°æ–¹æ³•éœ€è¦å®ƒä½œä¸ºå‚æ•°ä½†ä¼šåœ¨å¤±è´¥æ—¶å›é€€åˆ°ä¸šåŠ¡åº“å­˜å‚¨
            from bson import ObjectId
            fake_instance_id = ObjectId()
            
            # è°ƒç”¨å…ƒæ•°æ®ç®¡ç†å™¨çš„åŒé‡å­˜å‚¨æ–¹æ³•
            success = await self.metadata_manager.update_field_semantics(
                instance_name, fake_instance_id, database_name, collection_name, 
                field_path, business_meaning
            )
            
            return success
            
        except Exception as e:
            logger.error("ä½¿ç”¨å®ä¾‹åç§°æ›´æ–°å­—æ®µè¯­ä¹‰å¤±è´¥", error=str(e))
            return False