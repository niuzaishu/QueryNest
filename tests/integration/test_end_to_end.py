# -*- coding: utf-8 -*-
"""ç«¯åˆ°ç«¯é›†æˆæµ‹è¯• - æ¨¡æ‹Ÿå®Œæ•´çš„MCPå·¥å…·é“¾ä½¿ç”¨æµç¨‹"""

import pytest
import asyncio
from mcp.types import TextContent
from typing import Dict, Any

from .base_integration_test import BaseIntegrationTest
from .test_config import TEST_INSTANCE_CONFIG, TEST_DATA
import sys
from pathlib import Path
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from mcp_tools.instance_discovery import InstanceDiscoveryTool
from mcp_tools.database_discovery import DatabaseDiscoveryTool
from mcp_tools.collection_analysis import CollectionAnalysisTool
from mcp_tools.unified_semantic_tool import UnifiedSemanticTool
from mcp_tools.query_generation import QueryGenerationTool
from mcp_tools.query_confirmation import QueryConfirmationTool


@pytest.mark.integration
@pytest.mark.mongodb
class TestEndToEndWorkflow(BaseIntegrationTest):
    """ç«¯åˆ°ç«¯å·¥ä½œæµé›†æˆæµ‹è¯•ç±»"""
    
    async def setup_test_environment(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
        await super().async_setup_method()
        
        # åˆå§‹åŒ–å®ä¾‹å…ƒæ•°æ®åº“
        try:
            await self.metadata_manager.init_instance_metadata(TEST_INSTANCE_CONFIG["instance_id"])
            print("âœ“ å…ƒæ•°æ®åº“åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            print(f"âš ï¸  å…ƒæ•°æ®åº“åˆå§‹åŒ–å¤±è´¥ï¼ˆä½¿ç”¨ä¸šåŠ¡åº“å›é€€ï¼‰: {e}")
        
        # æ³¨å†Œæµ‹è¯•å®ä¾‹
        try:
            await self.metadata_manager.save_instance(TEST_INSTANCE_CONFIG["instance_id"], {
                "name": TEST_INSTANCE_CONFIG["instance_id"],
                "alias": TEST_INSTANCE_CONFIG["name"],
                "connection_string": TEST_INSTANCE_CONFIG["connection_string"],
                "description": "ç«¯åˆ°ç«¯æµ‹è¯•ç”¨å®ä¾‹",
                "environment": "test",
                "status": "active"
            })
            print("âœ“ å®ä¾‹ä¿¡æ¯ä¿å­˜æˆåŠŸ")
        except Exception as e:
            print(f"âš ï¸  å®ä¾‹ä¿¡æ¯ä¿å­˜åˆ°å…ƒæ•°æ®åº“å¤±è´¥ï¼ˆé¢„æœŸï¼‰: {e}")
    
    @pytest.mark.asyncio
    async def test_complete_discovery_to_query_workflow(self):
        """æµ‹è¯•ä»å‘ç°åˆ°æŸ¥è¯¢çš„å®Œæ•´å·¥ä½œæµ"""
        await self.setup_test_environment()
        
        try:
            # === æ­¥éª¤1: å‘ç°å¯ç”¨å®ä¾‹ ===
            instance_tool = InstanceDiscoveryTool(
                connection_manager=self.connection_manager,
                metadata_manager=self.metadata_manager
            )
            
            instance_result = await instance_tool.execute({
                "include_health": True,
                "include_stats": True
            })
            
            assert len(instance_result) == 1
            instance_text = instance_result[0].text
            assert TEST_INSTANCE_CONFIG["instance_id"] in instance_text
            print(f"âœ“ æ­¥éª¤1å®Œæˆ - å‘ç°å®ä¾‹: {len(instance_result)} ä¸ªç»“æœ")
            
            # === æ­¥éª¤2: å‘ç°æ•°æ®åº“ ===
            db_tool = DatabaseDiscoveryTool(
                connection_manager=self.connection_manager,
                metadata_manager=self.metadata_manager
            )
            
            db_result = await db_tool.execute({
                "instance_id": TEST_INSTANCE_CONFIG["instance_id"],
                "include_collections": True,
                "include_stats": True
            })
            
            assert len(db_result) == 1
            db_text = db_result[0].text
            assert "querynest_test" in db_text
            print(f"âœ“ æ­¥éª¤2å®Œæˆ - å‘ç°æ•°æ®åº“")
            
            # === æ­¥éª¤3: åˆ†æé›†åˆç»“æ„ ===
            analysis_tool = CollectionAnalysisTool(
                connection_manager=self.connection_manager,
                metadata_manager=self.metadata_manager,
                semantic_analyzer=self.semantic_analyzer
            )
            
            analysis_result = await analysis_tool.execute({
                "instance_id": TEST_INSTANCE_CONFIG["instance_id"],
                "database_name": "querynest_test",
                "collection_name": "users",
                "include_semantics": True,
                "include_examples": True,
                "include_indexes": True,
                "rescan": True
            })
            
            assert len(analysis_result) == 1
            analysis_text = analysis_result[0].text
            assert "users" in analysis_text
            assert "name" in analysis_text
            print(f"âœ“ æ­¥éª¤3å®Œæˆ - åˆ†æé›†åˆç»“æ„")
            
            # === æ­¥éª¤4: è¯­ä¹‰åˆ†æå’Œç®¡ç† ===
            semantic_tool = UnifiedSemanticTool(
                connection_manager=self.connection_manager,
                metadata_manager=self.metadata_manager,
                semantic_analyzer=self.semantic_analyzer
            )
            
            # æ‰§è¡Œæ‰¹é‡è¯­ä¹‰åˆ†æ
            semantic_result = await semantic_tool.execute({
                "action": "batch_analyze",
                "instance_id": TEST_INSTANCE_CONFIG["instance_id"],
                "database_name": "querynest_test", 
                "collection_name": "users"
            })
            
            assert len(semantic_result) == 1
            semantic_text = semantic_result[0].text
            assert "åˆ†æ" in semantic_text
            print(f"âœ“ æ­¥éª¤4å®Œæˆ - è¯­ä¹‰åˆ†æ")
            
            # === æ­¥éª¤5: ç”ŸæˆæŸ¥è¯¢ ===
            query_tool = QueryGenerationTool(
                connection_manager=self.connection_manager,
                metadata_manager=self.metadata_manager,
                semantic_analyzer=self.semantic_analyzer
            )
            
            query_result = await query_tool.execute({
                "instance_id": TEST_INSTANCE_CONFIG["instance_id"],
                "database_name": "querynest_test",
                "collection_name": "users",
                "query_description": "æŸ¥æ‰¾æŠ€æœ¯éƒ¨çš„æ‰€æœ‰å‘˜å·¥",
                "include_explanation": True,
                "output_format": "full"
            })
            
            assert len(query_result) == 1
            query_text = query_result[0].text
            assert "find" in query_text.lower() or "æŸ¥è¯¢" in query_text
            print(f"âœ“ æ­¥éª¤5å®Œæˆ - ç”ŸæˆæŸ¥è¯¢")
            
            # === æ­¥éª¤6: æ‰§è¡ŒæŸ¥è¯¢ç¡®è®¤ ===
            confirm_tool = QueryConfirmationTool(
                connection_manager=self.connection_manager,
                metadata_manager=self.metadata_manager
            )
            
            # æ„é€ ä¸€ä¸ªç®€å•çš„æŸ¥è¯¢æ¥æ‰§è¡Œ
            test_query = {
                "department": "æŠ€æœ¯éƒ¨"
            }
            
            confirm_result = await confirm_tool.execute({
                "instance_id": TEST_INSTANCE_CONFIG["instance_id"],
                "database_name": "querynest_test",
                "collection_name": "users",
                "query_type": "find",
                "mongodb_query": test_query,
                "limit": 10,
                "format_output": True
            })
            
            assert len(confirm_result) == 1
            confirm_text = confirm_result[0].text
            # åº”è¯¥åŒ…å«æŠ€æœ¯éƒ¨çš„å‘˜å·¥ï¼ˆå¼ ä¸‰å’Œç‹äº”ï¼‰
            assert "å¼ ä¸‰" in confirm_text or "ç‹äº”" in confirm_text
            print(f"âœ“ æ­¥éª¤6å®Œæˆ - æ‰§è¡ŒæŸ¥è¯¢ç¡®è®¤")
            
            print("ğŸ‰ å®Œæ•´å·¥ä½œæµæµ‹è¯•æˆåŠŸï¼")
            
        finally:
            await self.async_teardown_method()
    
    @pytest.mark.asyncio
    async def test_complex_analytical_workflow(self):
        """æµ‹è¯•å¤æ‚çš„åˆ†æå·¥ä½œæµ"""
        await self.setup_test_environment()
        
        try:
            # === æ­¥éª¤1: åˆ†ææ‰€æœ‰é›†åˆ ===
            analysis_tool = CollectionAnalysisTool(
                connection_manager=self.connection_manager,
                metadata_manager=self.metadata_manager,
                semantic_analyzer=self.semantic_analyzer
            )
            
            collections = ["users", "orders", "products"]
            collection_analyses = {}
            
            for collection_name in collections:
                result = await analysis_tool.execute({
                    "instance_id": TEST_INSTANCE_CONFIG["instance_id"],
                    "database_name": "querynest_test",
                    "collection_name": collection_name,
                    "include_semantics": True,
                    "include_examples": True,
                    "rescan": True
                })
                collection_analyses[collection_name] = result[0].text
                print(f"âœ“ åˆ†æå®Œæˆ: {collection_name}")
            
            # === æ­¥éª¤2: å»ºç«‹è¯­ä¹‰å…³ç³» ===
            semantic_tool = UnifiedSemanticTool(
                connection_manager=self.connection_manager,
                metadata_manager=self.metadata_manager,
                semantic_analyzer=self.semantic_analyzer
            )
            
            # ä¸ºå…³é”®å­—æ®µè®¾ç½®è¯­ä¹‰
            key_semantics = [
                {"collection": "users", "field": "name", "meaning": "ç”¨æˆ·å§“å"},
                {"collection": "users", "field": "department", "meaning": "æ‰€å±éƒ¨é—¨"},
                {"collection": "orders", "field": "user_id", "meaning": "ç”¨æˆ·æ ‡è¯†"},
                {"collection": "orders", "field": "product", "meaning": "äº§å“åç§°"},
                {"collection": "products", "field": "name", "meaning": "å•†å“åç§°"},
            ]
            
            for semantic in key_semantics:
                await semantic_tool.execute({
                    "action": "update",
                    "instance_id": TEST_INSTANCE_CONFIG["instance_id"],
                    "database_name": "querynest_test",
                    "collection_name": semantic["collection"],
                    "field_path": semantic["field"],
                    "business_meaning": semantic["meaning"]
                })
            
            print("âœ“ è¯­ä¹‰å…³ç³»å»ºç«‹å®Œæˆ")
            
            # === æ­¥éª¤3: æ‰§è¡Œå¤æ‚æŸ¥è¯¢ç”Ÿæˆ ===
            query_tool = QueryGenerationTool(
                connection_manager=self.connection_manager,
                metadata_manager=self.metadata_manager,
                semantic_analyzer=self.semantic_analyzer
            )
            
            complex_queries = [
                {
                    "collection": "users",
                    "description": "ç»Ÿè®¡å„éƒ¨é—¨çš„å‘˜å·¥æ•°é‡",
                    "expected_keywords": ["department", "count", "group"]
                },
                {
                    "collection": "orders",
                    "description": "æŸ¥æ‰¾é‡‘é¢è¶…è¿‡1000å…ƒçš„è®¢å•",
                    "expected_keywords": ["amount", "1000", "gt"]
                },
                {
                    "collection": "products",
                    "description": "æŸ¥æ‰¾ç”µå­äº§å“åˆ†ç±»ä¸‹çš„æ‰€æœ‰å•†å“",
                    "expected_keywords": ["category", "ç”µå­äº§å“"]
                }
            ]
            
            for query_spec in complex_queries:
                result = await query_tool.execute({
                    "instance_id": TEST_INSTANCE_CONFIG["instance_id"],
                    "database_name": "querynest_test",
                    "collection_name": query_spec["collection"],
                    "query_description": query_spec["description"],
                    "include_explanation": True,
                    "output_format": "full"
                })
                
                query_text = result[0].text
                print(f"âœ“ å¤æ‚æŸ¥è¯¢ç”Ÿæˆ: {query_spec['collection']} - {query_spec['description']}")
                
                # éªŒè¯æŸ¥è¯¢åŒ…å«é¢„æœŸå…³é”®è¯
                for keyword in query_spec["expected_keywords"]:
                    if keyword not in query_text:
                        print(f"âš ï¸  æŸ¥è¯¢å¯èƒ½ç¼ºå°‘å…³é”®è¯: {keyword}")
            
            print("ğŸ¯ å¤æ‚åˆ†æå·¥ä½œæµæµ‹è¯•æˆåŠŸï¼")
            
        finally:
            await self.async_teardown_method()
    
    @pytest.mark.asyncio
    async def test_error_resilience_workflow(self):
        """æµ‹è¯•é”™è¯¯æ¢å¤èƒ½åŠ›çš„å·¥ä½œæµ"""
        await self.setup_test_environment()
        
        try:
            # === æµ‹è¯•1: æ— æ•ˆå®ä¾‹å¤„ç† ===
            instance_tool = InstanceDiscoveryTool(
                connection_manager=self.connection_manager,
                metadata_manager=self.metadata_manager
            )
            
            # æµ‹è¯•æ­£å¸¸å®ä¾‹å‘ç°
            normal_result = await instance_tool.execute({})
            assert len(normal_result) == 1
            print("âœ“ æ­£å¸¸å®ä¾‹å‘ç°æµ‹è¯•é€šè¿‡")
            
            # === æµ‹è¯•2: æ— æ•ˆæ•°æ®åº“å¤„ç† ===
            db_tool = DatabaseDiscoveryTool(
                connection_manager=self.connection_manager,
                metadata_manager=self.metadata_manager
            )
            
            # æµ‹è¯•æ— æ•ˆå®ä¾‹ID
            invalid_result = await db_tool.execute({
                "instance_id": "nonexistent_instance"
            })
            assert len(invalid_result) == 1
            invalid_text = invalid_result[0].text
            assert "ä¸å­˜åœ¨" in invalid_text or "error" in invalid_text.lower()
            print("âœ“ æ— æ•ˆå®ä¾‹å¤„ç†æµ‹è¯•é€šè¿‡")
            
            # === æµ‹è¯•3: æŸ¥è¯¢ç”Ÿæˆå®¹é”™ ===
            query_tool = QueryGenerationTool(
                connection_manager=self.connection_manager,
                metadata_manager=self.metadata_manager,
                semantic_analyzer=self.semantic_analyzer
            )
            
            # æµ‹è¯•å¯¹ä¸å­˜åœ¨é›†åˆçš„æŸ¥è¯¢ç”Ÿæˆ
            try:
                error_result = await query_tool.execute({
                    "instance_id": TEST_INSTANCE_CONFIG["instance_id"],
                    "database_name": "querynest_test",
                    "collection_name": "nonexistent_collection",
                    "query_description": "æŸ¥æ‰¾ä¸å­˜åœ¨é›†åˆçš„æ•°æ®",
                    "include_explanation": True
                })
                # åº”è¯¥è¿”å›å‹å¥½çš„é”™è¯¯ä¿¡æ¯
                assert len(error_result) == 1
                error_text = error_result[0].text
                print(f"âœ“ é”™è¯¯æŸ¥è¯¢å¤„ç†: {error_text}")
            except Exception as e:
                print(f"âš ï¸  æŸ¥è¯¢å·¥å…·å¼‚å¸¸å¤„ç†: {e}")
            
            # === æµ‹è¯•4: è¯­ä¹‰ç®¡ç†å®¹é”™ ===
            semantic_tool = UnifiedSemanticTool(
                connection_manager=self.connection_manager,
                metadata_manager=self.metadata_manager,
                semantic_analyzer=self.semantic_analyzer
            )
            
            # æµ‹è¯•æœç´¢ä¸å­˜åœ¨çš„è¯­ä¹‰
            empty_search = await semantic_tool.execute({
                "action": "search",
                "instance_id": TEST_INSTANCE_CONFIG["instance_id"],
                "search_term": "ä¸å­˜åœ¨çš„è¯­ä¹‰å…³é”®è¯"
            })
            
            assert len(empty_search) == 1
            empty_text = empty_search[0].text
            assert "æœªæ‰¾åˆ°" in empty_text or "æ²¡æœ‰" in empty_text
            print("âœ“ ç©ºæœç´¢ç»“æœå¤„ç†æµ‹è¯•é€šè¿‡")
            
            print("ğŸ›¡ï¸  é”™è¯¯æ¢å¤èƒ½åŠ›æµ‹è¯•æˆåŠŸï¼")
            
        finally:
            await self.async_teardown_method()
    
    @pytest.mark.asyncio
    async def test_performance_workflow(self):
        """æµ‹è¯•æ€§èƒ½ç›¸å…³çš„å·¥ä½œæµ"""
        await self.setup_test_environment()
        
        try:
            import time
            
            # === æ€§èƒ½æµ‹è¯•1: å¿«é€Ÿå®ä¾‹å‘ç° ===
            start_time = time.time()
            
            instance_tool = InstanceDiscoveryTool(
                connection_manager=self.connection_manager,
                metadata_manager=self.metadata_manager
            )
            
            result = await instance_tool.execute({"include_health": True})
            
            discovery_time = time.time() - start_time
            assert discovery_time < 5.0, f"å®ä¾‹å‘ç°è€—æ—¶è¿‡é•¿: {discovery_time}ç§’"
            print(f"âœ“ å®ä¾‹å‘ç°æ€§èƒ½: {discovery_time:.2f}ç§’")
            
            # === æ€§èƒ½æµ‹è¯•2: æ‰¹é‡é›†åˆåˆ†æ ===
            start_time = time.time()
            
            analysis_tool = CollectionAnalysisTool(
                connection_manager=self.connection_manager,
                metadata_manager=self.metadata_manager,
                semantic_analyzer=self.semantic_analyzer
            )
            
            # å¹¶å‘åˆ†æå¤šä¸ªé›†åˆ
            analysis_tasks = []
            for collection_name in ["users", "orders", "products"]:
                task = analysis_tool.execute({
                    "instance_id": TEST_INSTANCE_CONFIG["instance_id"],
                    "database_name": "querynest_test",
                    "collection_name": collection_name,
                    "include_semantics": True,
                    "rescan": True
                })
                analysis_tasks.append(task)
            
            await asyncio.gather(*analysis_tasks)
            
            analysis_time = time.time() - start_time
            assert analysis_time < 30.0, f"æ‰¹é‡åˆ†æè€—æ—¶è¿‡é•¿: {analysis_time}ç§’"
            print(f"âœ“ æ‰¹é‡åˆ†ææ€§èƒ½: {analysis_time:.2f}ç§’")
            
            # === æ€§èƒ½æµ‹è¯•3: å¿«é€ŸæŸ¥è¯¢ç”Ÿæˆ ===
            start_time = time.time()
            
            query_tool = QueryGenerationTool(
                connection_manager=self.connection_manager,
                metadata_manager=self.metadata_manager,
                semantic_analyzer=self.semantic_analyzer
            )
            
            await query_tool.execute({
                "instance_id": TEST_INSTANCE_CONFIG["instance_id"],
                "database_name": "querynest_test",
                "collection_name": "users",
                "query_description": "æŸ¥æ‰¾æ‰€æœ‰ç”¨æˆ·",
                "output_format": "executable"  # ä½¿ç”¨é«˜æ€§èƒ½çš„ç®€æ´æ ¼å¼
            })
            
            query_time = time.time() - start_time
            assert query_time < 10.0, f"æŸ¥è¯¢ç”Ÿæˆè€—æ—¶è¿‡é•¿: {query_time}ç§’"
            print(f"âœ“ æŸ¥è¯¢ç”Ÿæˆæ€§èƒ½: {query_time:.2f}ç§’")
            
            print("âš¡ æ€§èƒ½æµ‹è¯•é€šè¿‡ï¼")
            
        finally:
            await self.async_teardown_method()